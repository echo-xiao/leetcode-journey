import os
import requests
import json
import time
from openai import OpenAI
from tqdm import tqdm
from dotenv import load_dotenv

# 1. åˆå§‹åŒ–
load_dotenv()
client = OpenAI(api_key=os.getenv('CHATGPT_TOKEN'))

# --- ç¯å¢ƒæ£€æŸ¥ ---
LC_SESSION = os.getenv('LEETCODE_SESSION')
LC_CSRF = os.getenv('LEETCODE_CSRFTOKEN')
OPENAI_KEY = os.getenv('CHATGPT_TOKEN')

# ================= æ ¸å¿ƒï¼šèº«ä»½éªŒè¯ Session é…ç½® =================
# åˆ›å»ºä¸€ä¸ªå…¨å±€ Session å¯¹è±¡ï¼Œå®ƒä¼šè‡ªåŠ¨ç®¡ç† Cookie å’Œ Header
session = requests.Session()

# æ³¨å…¥èº«ä»½ Cookieï¼ˆè§£å†³ 0 é¢˜é—®é¢˜çš„å…³é”®ï¼‰
session.cookies.set('LEETCODE_SESSION', LC_SESSION, domain='leetcode.com')
session.cookies.set('csrftoken', LC_CSRF, domain='leetcode.com')

# è®¾ç½®å…¨å±€é€šç”¨çš„ Header
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
    'Referer': 'https://leetcode.com',
    'x-csrftoken': LC_CSRF,
    'Content-Type': 'application/json'
})

print(f"--- ç¯å¢ƒæ£€æŸ¥ ---")
print(f"Debug - Session: {LC_SESSION[:15] if LC_SESSION else 'None'}...")
print(f"Debug - CSRF: {LC_CSRF[:15] if LC_CSRF else 'None'}...")
print(f"Debug - OpenAI Key: {'å·²æ‰¾åˆ°' if OPENAI_KEY else 'æœªæ‰¾åˆ°'}")
print(f"----------------\n")

# ================= é…ç½®åŒº =================
TEST_MODE = False  # â­ True: ä»…æµ‹è¯• 10 é¢˜; False: å…¨é‡åŒæ­¥ 364+ é¢˜
TEST_LIMIT = 10
BASE_URL_EN = "https://leetcode.com"
BASE_URL_CN = "https://leetcode.cn"


# ================= åŠŸèƒ½å‡½æ•°ï¼ˆå·²åˆ‡æ¢è‡³ sessionï¼‰ =================

def get_total_ac_count():
    """è·å–ç”¨æˆ· AC é¢˜ç›®çš„çœŸå®æ€»æ•°"""
    # ä¹Ÿå¯ä»¥ç›´æ¥è®¿é—® api/problems/all/ è·å– num_solvedï¼Œæ›´ç›´æ¥
    url = f"{BASE_URL_EN}/api/problems/all/"
    try:
        resp = session.get(url)  # ä½¿ç”¨ session å‘èµ·è¯·æ±‚
        data = resp.json()
        # é¡ºä¾¿æ‰“å°ä¸€ä¸‹å½“å‰ç”¨æˆ·åï¼Œç¡®è®¤æ²¡èµ°é”™æˆ¿é—´
        print(f"ğŸ‘¤ å½“å‰ç™»å½•ç”¨æˆ·: {data.get('user_name', 'æœªçŸ¥')}")
        return data.get('num_solved', 0)
    except Exception as e:
        print(f"è·å–æ€»æ•°å¤±è´¥: {e}")
        return 0


def get_all_ac_questions(session):
    """
    åˆ†é¡µè·å–æ‰€æœ‰é€šè¿‡é¢˜ç›®çš„ Slug
    """
    total = get_total_ac_count()
    print(f"ğŸ“Š è´¦æˆ·å†…å·²é€šè¿‡é¢˜ç›®æ€»æ•°: {total}")

    questions = []
    page_size = 100

    # 1. æ›´æ–°åçš„æŸ¥è¯¢è¯­å¥ï¼ŒåŠ å…¥äº† $categorySlug å‚æ•°
    query = """
    query problemsetQuestionList($limit: Int, $skip: Int, $filters: QuestionListFilterInput, $categorySlug: String) {
      problemsetQuestionList: questionList(limit: $limit, skip: $skip, filters: $filters, categorySlug: $categorySlug) {
        questions: data { questionId titleSlug }
      }
    }
    """

    for skip in range(0, total, page_size):
        # 2. åœ¨ vars ä¸­å¢åŠ  categorySlugï¼Œä¼ ç©ºå­—ç¬¦ä¸² "" ä»£è¡¨è·å–æ‰€æœ‰åˆ†ç±»
        vars = {
            "limit": page_size,
            "skip": skip,
            "filters": {"status": "AC"},
            "categorySlug": ""  # è¿™é‡Œçš„ç©ºå­—ç¬¦ä¸²æ˜¯è§£å†³é—®é¢˜çš„å…³é”®
        }

        try:
            resp = session.post(
                f"{BASE_URL_EN}/graphql",
                json={'query': query, 'variables': vars},
                timeout=10
            )

            data = resp.json()
            if 'data' in data and data['data']['problemsetQuestionList']:
                questions.extend(data['data']['problemsetQuestionList']['questions'])
                print(f"âœ… å·²æŠ“å– {len(questions)} / {total}")
            else:
                print(f"âš ï¸ å“åº”å¼‚å¸¸: {data}")
                break

            time.sleep(0.8)
        except Exception as e:
            print(f"âŒ è¯·æ±‚å‡ºé”™: {e}")
            break

    return questions



def get_problem_details(slug):
    """è·¨ç«™è·å–å…ƒæ•°æ®ä¸ä¸­æ–‡å†…å®¹"""
    q_meta = """
    query singleQuestion($titleSlug: String!) {
      question(titleSlug: $titleSlug) {
        questionId difficulty
        topicTags { name translatedName }
      }
    }
    """
    q_cn = """
    query translatedConfig($titleSlug: String!) {
      question(titleSlug: $titleSlug) { translatedTitle translatedContent }
    }
    """
    try:
        meta = \
        session.post(f"{BASE_URL_EN}/graphql", json={'query': q_meta, 'variables': {'titleSlug': slug}}).json()['data'][
            'question']
        # ä¸­æ–‡ç«™ä¸éœ€è¦èº«ä»½éªŒè¯ï¼Œç›´æ¥è¯·æ±‚
        cn = \
        requests.post(f"{BASE_URL_CN}/graphql", json={'query': q_cn, 'variables': {'titleSlug': slug}}).json()['data'][
            'question']
        tags = [t['translatedName'] or t['name'] for t in meta.get('topicTags', [])]
        return meta['questionId'], meta['difficulty'], tags, cn
    except:
        return None, "Unknown", [], None


def get_all_ac_submissions(slug):
    """è·å–è¯¥é¢˜ç›®ä¸‹æ‰€æœ‰ AC æäº¤è®°å½•"""
    all_ac_subs = []
    offset, limit = 0, 20
    query = """
    query submissionList($questionSlug: String!, $offset: Int, $limit: Int) {
        submissionList(questionSlug: $questionSlug, offset: $offset, limit: $limit) {
            submissions { id statusDisplay lang timestamp }
        }
    }
    """
    while True:
        vars = {'offset': offset, 'limit': limit, 'questionSlug': slug}
        try:
            resp = session.post(f"{BASE_URL_EN}/graphql", json={'query': query, 'variables': vars}).json()
            subs = resp.get('data', {}).get('submissionList', {}).get('submissions', [])
            if not subs: break
            ac_in_page = [s for s in subs if s['statusDisplay'] == 'Accepted']
            all_ac_subs.extend(ac_in_page)
            offset += limit
            time.sleep(0.3)
        except:
            break
    return all_ac_subs


def get_submission_code(sub_id):
    """è·å–å…·ä½“ä»£ç """
    query = "query submissionDetails($submissionId: Int!) { submissionDetails(submissionId: $submissionId) { code } }"
    try:
        resp = session.post(f"{BASE_URL_EN}/graphql",
                            json={'query': query, 'variables': {'submissionId': int(sub_id)}}).json()
        return resp.get('data', {}).get('submissionDetails', {}).get('code', "")
    except:
        return ""


def ai_analyze_all_versions(title, codes_dict):
    """GPT-4o ç»¼åˆåˆ†ææ‰€æœ‰ AC ç‰ˆæœ¬"""
    code_context = ""
    for i, (key, code) in enumerate(codes_dict.items()):
        code_context += f"--- ç‰ˆæœ¬ {i + 1} (ID: {key}) ---\n{code}\n\n"

    prompt = (
        f"è¯·åˆ†æç®—æ³•é¢˜ã€Š{title}ã€‹çš„æ‰€æœ‰ AC ç‰ˆæœ¬å®ç°é€»è¾‘ã€‚\n"
        f"è¦æ±‚ï¼š\n"
        f"1. ä¸€å¥è¯ç›´å‡»æœ¬è´¨ï¼šç”¨ä¸€å¥è¯æ€»ç»“è¯¥ç®—æ³•çš„æ ¸å¿ƒé€»è¾‘ã€‚\n"
        f"2. ç»¼åˆæ€è·¯ï¼šå¦‚æœå­˜åœ¨å¤šç§è§£æ³•ï¼ˆå¦‚é€’å½’ä¸è¿­ä»£ã€DFSä¸BFSã€ä¸åŒæ•°æ®ç»“æ„ï¼‰ï¼Œè¯·åˆ†åˆ«ç®€è¿°ã€‚\n"
        f"3. å…¨é‡ä¼ªä»£ç ï¼šæ€»ç»“æ‰€æœ‰ AC ç‰ˆæœ¬ä¸­æ¶‰åŠçš„ä¸åŒç±»å‹é€»è¾‘çš„ä¸­æ–‡ä¼ªä»£ç ã€‚\n"
        f"4. å¤æ‚åº¦ï¼šä½¿ç”¨ LaTeX æ ¼å¼ç»™å‡ºæ—¶é—´åŠç©ºé—´å¤æ‚åº¦ï¼Œä¾‹å¦‚ $O(n)$ã€‚\n\n"
        f"ä»£ç é›†å¦‚ä¸‹ï¼š\n{code_context}"
    )
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç®—æ³•ä¸“å®¶ã€‚"}, {"role": "user", "content": prompt}],
            temperature=0.2
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"AI å¤ç›˜ç”Ÿæˆå¤±è´¥: {e}"


def classify_question(tags, title):
    """
    æ ¹æ®æ ‡ç­¾å’Œæ ‡é¢˜ï¼Œå°†é¢˜ç›®å½’ç±»åˆ°ä½ æä¾›çš„ 12 å¤§ç±»ä¸­
    è¿”å›: (å¤§ç±»åç§°, å°ç±»å»ºè®®)
    """
    tag_set = set(tags)

    # æ˜ å°„é…ç½® (å¤§ç±»å…³é”®å­— -> å¯¹åº”çš„ LeetCode æ ‡ç­¾æˆ–å…³é”®å­—)
    mapping = {
        "1. æ»‘åŠ¨çª—å£ä¸åŒæŒ‡é’ˆ": ["Sliding Window", "Two Pointers", "åŒæŒ‡é’ˆ", "æ»‘åŠ¨çª—å£"],
        "2. äºŒåˆ†ç®—æ³•": ["Binary Search", "äºŒåˆ†æŸ¥æ‰¾"],
        "3. å•è°ƒæ ˆ": ["Monotonic Stack", "å•è°ƒæ ˆ"],
        "4. ç½‘æ ¼å›¾": ["Matrix", "Grid", "çŸ©é˜µ"],
        "5. ä½è¿ç®—": ["Bit Manipulation", "ä½è¿ç®—"],
        "6. å›¾è®ºç®—æ³•": ["Graph", "Topological Sort", "Shortest Path", "Minimum Spanning Tree", "å›¾", "æ‹“æ‰‘æ’åº"],
        "7. åŠ¨æ€è§„åˆ’": ["Dynamic Programming", "èƒŒåŒ…é—®é¢˜", "çŠ¶æ€å‹ç¼©", "åŠ¨æ€è§„åˆ’"],
        "8. å¸¸ç”¨æ•°æ®ç»“æ„": ["Stack", "Queue", "Heap (Priority Queue)", "Trie", "Union Find", "Fenwick Tree",
                            "Segment Tree", "Prefix Sum", "å †", "å¹¶æŸ¥é›†", "å‰ç¼€å’Œ"],
        "9. æ•°å­¦ç®—æ³•": ["Math", "Number Theory", "Combinatorics", "Geometry", "æ•°å­¦", "æ•°è®º", "ç»„åˆæ•°å­¦"],
        "10. è´ªå¿ƒä¸æ€ç»´": ["Greedy", "Brainteaser", "è´ªå¿ƒ", "è„‘ç­‹æ€¥è½¬å¼¯"],
        "11. é“¾è¡¨ã€æ ‘ä¸å›æº¯": ["Linked List", "Tree", "Binary Tree", "Backtracking", "Depth-First Search",
                              "Breadth-First Search", "å›æº¯", "äºŒå‰æ ‘", "æ·±åº¦ä¼˜å…ˆæœç´¢"],
        "12. å­—ç¬¦ä¸²": ["String", "String Matching", "å­—ç¬¦ä¸²", "KMP"]
    }

    # ä¼˜å…ˆçº§åŒ¹é…
    for main_cat, keywords in mapping.items():
        if any(k.lower() in [t.lower() for t in tags] for k in keywords):
            # ç®€å•å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ ‡ç­¾ä½œä¸ºå°ç±»ï¼Œæˆ–æ ¹æ®å­ç±»é€»è¾‘ç»†åŒ–
            sub_cat = tags[0] if tags else "é€šç”¨"
            return main_cat, sub_cat

    return "13. å…¶ä»–", "æœªåˆ†ç±»"

# ================= ä¸»ç¨‹åº =================
def classify_question(tags, title):
    """
    æ ¸å¿ƒåˆ†ç±»é€»è¾‘ï¼šåŸºäº LeetCode æ ‡ç­¾å°†é¢˜ç›®æ˜ å°„è‡³ 12 å¤§ç±»ä½“ç³»
    """
    tag_set = {t.lower() for t in tags}

    # æ˜ å°„é…ç½®ï¼šå¤§ç±»åç§° -> åŒ¹é…çš„ LeetCode è‹±æ–‡æ ‡ç­¾æˆ–å…³é”®å­—
    mapping = {
        "1. æ»‘åŠ¨çª—å£ä¸åŒæŒ‡é’ˆ": ["sliding window", "two pointers", "åŒæŒ‡é’ˆ", "æ»‘åŠ¨çª—å£"],
        "2. äºŒåˆ†ç®—æ³•": ["binary search", "äºŒåˆ†æŸ¥æ‰¾", "äºŒåˆ†"],
        "3. å•è°ƒæ ˆ": ["monotonic stack", "å•è°ƒæ ˆ", "å•è°ƒé˜Ÿåˆ—"],
        "4. ç½‘æ ¼å›¾": ["matrix", "grid", "çŸ©é˜µ"],
        "5. ä½è¿ç®—": ["bit manipulation", "ä½è¿ç®—"],
        "6. å›¾è®ºç®—æ³•": ["graph", "topological sort", "shortest path", "minimum spanning tree", "å›¾", "æ‹“æ‰‘æ’åº"],
        "7. åŠ¨æ€è§„åˆ’": ["dynamic programming", "backpack", "memoization", "åŠ¨æ€è§„åˆ’"],
        "8. å¸¸ç”¨æ•°æ®ç»“æ„": ["stack", "queue", "heap", "priority queue", "trie", "union find", "fenwick tree",
                            "segment tree", "prefix sum", "hash table", "å †", "å¹¶æŸ¥é›†", "å‰ç¼€å’Œ"],
        "9. æ•°å­¦ç®—æ³•": ["math", "number theory", "combinatorics", "geometry", "probability", "æ•°å­¦", "æ•°è®º",
                        "ç»„åˆæ•°å­¦"],
        "10. è´ªå¿ƒä¸æ€ç»´": ["greedy", "brainteaser", "constructive", "è´ªå¿ƒ", "è„‘ç­‹æ€¥è½¬å¼¯"],
        "11. é“¾è¡¨ã€æ ‘ä¸å›æº¯": ["linked list", "tree", "binary tree", "backtracking", "dfs", "bfs", "depth-first search",
                              "breadth-first search", "é“¾è¡¨", "äºŒå‰æ ‘", "å›æº¯"],
        "12. å­—ç¬¦ä¸²": ["string", "string matching", "kmp", "ac automaton", "å­—ç¬¦ä¸²"]
    }

    for main_cat, keywords in mapping.items():
        if any(k in tag_set for k in keywords):
            # å–ç¬¬ä¸€ä¸ªåŸå§‹æ ‡ç­¾ä½œä¸ºå°ç±»ï¼Œè‹¥æ— åˆ™è®¾ä¸º General
            sub_cat = tags[0] if tags else "General"
            return main_cat, sub_cat

    return "13. å…¶ä»–", "æœªåˆ†ç±»"


def main():
    print("ğŸš€ å¼€å§‹è¿è¡Œ LeetCode åŒæ­¥ç¨‹åº...")
    all_questions = get_all_ac_questions(session)

    if not all_questions:
        print("âŒ æœªè·å–åˆ°é¢˜ç›®ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return

    if TEST_MODE:
        print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼å¼€å¯ï¼šä»…å¤„ç†å‰ {TEST_LIMIT} é¢˜")
        all_questions = all_questions[:TEST_LIMIT]

    if not os.path.exists("Problems"):
        os.makedirs("Problems")

    # ç”¨äºç”Ÿæˆ summary.json çš„æ±‡æ€»åˆ—è¡¨
    summary_data = []

    for q_basic in tqdm(all_questions, desc="ğŸ“¦ æ·±åº¦åŒæ­¥ä¸­"):
        slug = q_basic['titleSlug']
        try:
            q_id, difficulty, tags, prob_cn = get_problem_details(slug)
            cn_title = (prob_cn['translatedTitle'] if prob_cn else slug) or slug
            folder = f"Problems/{q_id}_{slug}"

            # 1. è‡ªåŠ¨åˆ†ç±»
            main_cat, sub_cat = classify_question(tags, cn_title)

            # 2. æ”¶é›† JSON æ•°æ® (åŒ…å« 6 ä¸ªæ ¸å¿ƒå­—æ®µ)
            summary_data.append({
                "id": q_id,
                "title_cn": cn_title,
                "title_en": slug,
                "difficulty": difficulty,
                "category_main": main_cat,
                "category_sub": sub_cat,
                "tags": tags
            })

            # æ–­ç‚¹ç»­ä¼ 
            if os.path.exists(f"{folder}/README_CN.md") and not TEST_MODE:
                continue

            os.makedirs(folder, exist_ok=True)
            ac_subs = get_all_ac_submissions(slug)
            if not ac_subs: continue

            all_codes = {}
            for i, sub in enumerate(ac_subs):
                code = get_submission_code(sub['id'])
                if not code: continue
                lang = sub['lang']
                ext = {"python": "py", "python3": "py", "java": "java", "cpp": "cpp", "javascript": "js"}.get(lang,
                                                                                                              "txt")

                with open(f"{folder}/solution_{i + 1}.{ext}", 'w', encoding='utf-8') as f:
                    f.write(code)
                all_codes[f"{sub['id']}_{lang}"] = code

            # AI ç»¼åˆåˆ†æ
            analysis = ai_analyze_all_versions(cn_title, all_codes)

            # 3. å†™å…¥ Markdownï¼ŒåŒæ—¶æ ‡æ³¨åˆ†ç±»
            with open(f"{folder}/README_CN.md", 'w', encoding='utf-8') as f:
                tag_str = " ".join([f"`{t}`" for t in tags])
                f.write(f"# {q_id}. {cn_title}\n\n")
                f.write(f"**éš¾åº¦**: {difficulty} | **æ ‡ç­¾**: {tag_str}\n\n")
                f.write(f"**å½’ç±»**: {main_cat} > {sub_cat}\n\n")
                f.write(f"## é¢˜ç›®æè¿°\n\n{prob_cn['translatedContent'] if prob_cn else 'æš‚æ— æè¿°'}\n\n---\n")
                f.write(f"## è§£é¢˜æ€è·¯ä¸å¤ç›˜\n\n{analysis}")

            time.sleep(0.5)

        except Exception as e:
            print(f"\nâŒ å¤„ç† {slug} å‡ºé”™: {e}")
            continue

    # 4. æŒä¹…åŒ– summary.json
    with open("summary.json", "w", encoding="utf-8") as f:
        json.dump(summary_data, f, ensure_ascii=False, indent=4)

    print(f"\nâœ… åŒæ­¥å®Œæˆï¼summary.json å·²æ›´æ–°ï¼Œå…±è®¡ {len(summary_data)} é¢˜ã€‚")




if __name__ == "__main__":
    main()
